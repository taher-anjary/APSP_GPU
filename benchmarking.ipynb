{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilss import benchmark, save_to_json, load_from_json, sort_by_and_plot\n",
    "from apsp import FW_GPU, R_Kleene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Random Graph Generator ####\n",
    "# def graph_gen(num_nodes=10, density_controller=.9, cost_magnitude_controller=100):\n",
    "#     cuda0 = torch.device('cuda:0')\n",
    "#     dc= density_controller # less than one makes it sparser, greater than one makes it denser\n",
    "#     cmc = cost_magnitude_controller # controls the magnitude of the costs\n",
    "\n",
    "#     dense_adj = torch.bernoulli(torch.clamp(dc*torch.rand(num_nodes, num_nodes), max=1.0)).to(cuda0).int()\n",
    "#     dense_adj[torch.arange(num_nodes), torch.arange(num_nodes)] = 0\n",
    "#     num_edges = dense_adj.sum() # count the total number of edges generated in this graph\n",
    "\n",
    "#     costs = (cmc * torch.rand(dense_adj.shape).to(cuda0))#.int()\n",
    "#     costs[~dense_adj.bool()] = torch.inf \n",
    "#     costs[torch.arange(num_nodes), torch.arange(num_nodes)] = 0\n",
    "    \n",
    "#     return costs, num_edges.item()\n",
    "\n",
    "# ### Converter to nx Graph\n",
    "# def convert_to_nxg(H):\n",
    "\n",
    "#     H_sparse = H.to_sparse()\n",
    "#     edge_index, weight = H_sparse.indices().cpu().numpy(), H_sparse.values().cpu().numpy()\n",
    "#     edge_and_weights = [(edge[0], edge[1], w) for edge, w in zip(edge_index.T, weight.T)]\n",
    "\n",
    "#     g = nx.Graph()\n",
    "#     g.add_weighted_edges_from(edge_and_weights)\n",
    "\n",
    "#     return g\n",
    "\n",
    "# #### FLOYD WARSHALL ALGS ####\n",
    "# def FW_GPU(H):\n",
    "#     found = False\n",
    "#     while not found:\n",
    "#         H_prime, pred = FW_iter(H.clone())\n",
    "#         if (H_prime == H).all():\n",
    "#             found=True\n",
    "#         H = H_prime\n",
    "#     return {'cost': H, 'pred': pred}\n",
    "\n",
    "# def FW_iter(costs):\n",
    "#     threeD = costs + costs.T.unsqueeze(1)\n",
    "#     updated_costs, updated_vias = torch.min(threeD, dim=2)\n",
    "#     updated_costs, updated_vias = updated_costs.T, updated_vias.T\n",
    "#     return updated_costs, updated_vias\n",
    "\n",
    "# #### R-KLEENE ALGS ####\n",
    "# def min_plus_GPU(A, B, C=None):\n",
    "#     threeD = A + B.T.unsqueeze(1)\n",
    "#     updated_costs, updated_vias = torch.min(threeD, dim=2)\n",
    "#     updated_costs, updated_vias = updated_costs.T, updated_vias.T\n",
    "#     if C is None:\n",
    "#         return updated_costs #, updated_vias\n",
    "#     else:\n",
    "#         return torch.minimum(updated_costs, C) #, updated_vias\n",
    "\n",
    "# def R_Kleene(H):\n",
    "#     h,w = H.shape\n",
    "#     assert h == w, 'The input cost matrix should be square'\n",
    "#     assert (H >= 0).any(), \"The input cost matrix shouldn't have negative costs \"\n",
    "#     assert (torch.diagonal(H) == 0).all(), 'The input cost matrix should have a zero diagonal'\n",
    "\n",
    "#     # base case\n",
    "#     if h <= 2:\n",
    "#         return H\n",
    "\n",
    "#     # recursive case\n",
    "#     cut_point = h//2\n",
    "#     A = H[:cut_point, :cut_point]\n",
    "#     B = H[:cut_point, cut_point:]\n",
    "#     C = H[cut_point:, :cut_point]\n",
    "#     D = H[cut_point:, cut_point:]\n",
    "\n",
    "#     A = R_Kleene(A);          # recursive call, compute path lengths within A\n",
    "#     B = min_plus_GPU(A,B);    # B = A*B;       now B includes paths through A\n",
    "#     C = min_plus_GPU(C,A);    # C = C*A;       now C includes paths through A\n",
    "#     D = min_plus_GPU(C,B,D);  # D = D + C*B;   now D includes paths through A\n",
    "#     D = R_Kleene(D);          # recursive call, compute path lengths within D\n",
    "#     B = min_plus_GPU(B,D);    # B = B*D;       now B includes paths through D\n",
    "#     C = min_plus_GPU(D,C);    # C = D*C:       now C includes paths through D\n",
    "#     A = min_plus_GPU(B,C,A);  # A = A + B*C;   now A includes paths through D\n",
    "\n",
    "#     result = torch.cat([ torch.cat([A, B], dim=1), torch.cat([C, D], dim=1) ], dim=0)\n",
    "#     return result\n",
    "\n",
    "# #### BENCHMARKING #######\n",
    "# def benchmark(num_exps=500, max_nodes=1000, max_density=100, do_nx=False):\n",
    "\n",
    "#     num_nodess = torch.randint(4,max_nodes,size=(1,num_exps)).flatten()\n",
    "#     densities = torch.randint(0,max_density,size=(1,num_exps)).flatten() * torch.rand(num_exps)\n",
    "#     num_edgess = num_exps * [None]\n",
    "\n",
    "#     fw_cc, rkl_cc, nx_cc = num_exps * [None], num_exps * [None], num_exps * [None]\n",
    "#     inconsistencies_kl_fw, inconsistencies_nx_rkl, inconsistencies_nx_fw = num_exps * [None], num_exps * [None], num_exps * [None]\n",
    "\n",
    "#     for exp, (num_nodes, density) in enumerate(zip(num_nodess, densities)):\n",
    "#         H, num_edges = graph_gen(num_nodes=num_nodes, density_controller=density) \n",
    "#         num_edgess[exp] = num_edges\n",
    "\n",
    "#         curr = time.time()\n",
    "#         H_fw = FW_GPU(H.clone())['cost']\n",
    "#         fw_cc[exp] = time.time() - curr\n",
    "#         #H_fw = torch.round(H_fw) #, decimal=2)\n",
    "\n",
    "#         curr = time.time()\n",
    "#         H_rkl = R_Kleene(H.clone())\n",
    "#         rkl_cc[exp] = time.time() - curr\n",
    "#         #H_rkl = torch.round(H_rkl) #, decimal=2)\n",
    "\n",
    "#         if do_nx:\n",
    "#             g = convert_to_nxg(H)\n",
    "#             curr = time.time()\n",
    "#             H_nx = nx.floyd_warshall_numpy(g)\n",
    "#             nx_cc[exp] = time.time() - curr\n",
    "\n",
    "#             H_nx = torch.Tensor(H_nx).to(H.device)\n",
    "\n",
    "#             inconsistency_nx_fw = torch.nn.functional.mse_loss(H_nx, H_fw)\n",
    "#             inconsistencies_nx_fw[exp] = inconsistency_nx_fw.item()\n",
    "            \n",
    "#             inconsistency_nx_rkl = torch.nn.functional.mse_loss(H_nx, H_rkl)\n",
    "#             inconsistencies_nx_rkl[exp] = inconsistency_nx_rkl.item()\n",
    "\n",
    "#         #assert (H_rkl == H_fw).all(), 'Inconsistent Results between GPU algs!'\n",
    "#         inconsistency_kl_fw = torch.nn.functional.mse_loss(H_rkl, H_fw)\n",
    "#         inconsistencies_kl_fw[exp] = inconsistency_kl_fw.item()\n",
    "\n",
    "\n",
    "#     # Format\n",
    "#     num_nodess = num_nodess.cpu().numpy()\n",
    "#     num_edgess = np.array(num_edgess)\n",
    "\n",
    "#     rkl_cc = np.array(rkl_cc)\n",
    "#     fw_cc = np.array(fw_cc)\n",
    "#     nx_cc = np.array(nx_cc)\n",
    "\n",
    "#     inconsistencies_kl_fw = np.array(inconsistencies_kl_fw)\n",
    "#     inconsistencies_nx_fw = np.array(inconsistencies_nx_fw)\n",
    "#     inconsistencies_nx_rkl = np.array(inconsistencies_nx_rkl)\n",
    "\n",
    "#     return {'graph_specs': [num_nodess, num_edgess], 'time_costs': [rkl_cc, fw_cc, nx_cc], 'inconsistencies': [inconsistencies_kl_fw, inconsistencies_nx_fw, inconsistencies_nx_rkl]}\n",
    "\n",
    "# def sort_by_and_plot(big_dict, sort_by='nodes', do_nx=False, exp_slice=None): # num_nodess, num_edgess, rkl_cc, fw_cc, inconsistencies,\n",
    "#     num_nodess, num_edgess = big_dict['graph_specs']\n",
    "#     rkl_cc, fw_cc, nx_cc = big_dict['time_costs']\n",
    "#     inconsistencies_kl_fw, inconsistencies_nx_fw, inconsistencies_nx_rkl = big_dict['inconsistencies']\n",
    "\n",
    "#     if exp_slice is None:\n",
    "#         start, stop = 0, num_nodess.shape[0]\n",
    "#     else:\n",
    "#         start, stop = exp_slice\n",
    "\n",
    "#     # Sort\n",
    "#     if sort_by == 'nodes':\n",
    "#         sorting_idxs = np.argsort(num_nodess)\n",
    "#     elif sort_by == 'edges':\n",
    "#         sorting_idxs = np.argsort(num_edgess)\n",
    "#     num_nodess = num_nodess[sorting_idxs][start:stop]\n",
    "#     num_edgess = num_edgess[sorting_idxs][start:stop]\n",
    "#     rkl_cc = rkl_cc[sorting_idxs][start:stop]\n",
    "#     fw_cc = fw_cc[sorting_idxs][start:stop]\n",
    "#     nx_cc = nx_cc[sorting_idxs][start:stop]\n",
    "#     inconsistencies_kl_fw = inconsistencies_kl_fw[sorting_idxs][start:stop]\n",
    "#     inconsistencies_nx_fw = inconsistencies_nx_fw[sorting_idxs][start:stop]\n",
    "#     inconsistencies_nx_rkl = inconsistencies_nx_rkl[sorting_idxs][start:stop]\n",
    "\n",
    "#     # Plots\n",
    "#     plt.figure()\n",
    "#     plt.plot(num_nodess, label='num nodes of graph')\n",
    "#     plt.plot(np.sqrt(num_edgess), label='num edges of graph in sqrt scale')\n",
    "#     plt.xlabel('graph/exp number')\n",
    "#     plt.ylabel('amount')\n",
    "#     plt.title('Showing graph statistics of each graph-experimental-sample')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure()\n",
    "#     graph_densities = num_edgess / ((num_nodess**2) - num_nodess)\n",
    "#     plt.plot(graph_densities, label='graph density')\n",
    "#     plt.xlabel('graph/exp number')\n",
    "#     plt.ylabel('Graph Density')\n",
    "#     plt.title('Showing connectivity/density of each graph-experiment-sample')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(fw_cc, label='FW_GPU() time costs')\n",
    "#     plt.plot(rkl_cc, label='R_Kleene_GPU() time costs')\n",
    "#     if do_nx:\n",
    "#         plt.plot(nx_cc, label='FW_CPU_NX() time costs')\n",
    "#     plt.xlabel('graph/exp number')\n",
    "#     plt.ylabel('time cost in seconds')\n",
    "#     plt.title('Comparing Time Costs of APSP Implementations')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(inconsistencies_kl_fw, label='between FW_GPU() and R_Kleene_GPU()')\n",
    "#     if do_nx:\n",
    "#         plt.plot(inconsistencies_nx_fw, label='between FW_CPU_NX() and FW_GPU()')\n",
    "#         plt.plot(inconsistencies_nx_rkl, label='between FW_CPU_NX() and R_Kleene_GPU()')\n",
    "#     plt.xlabel('graph/exp number')\n",
    "#     plt.ylabel('Average Mean Squared Error(MSE)')\n",
    "#     plt.title('Quantifying Inconsitencies Between APSP Implementations')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# def save_to_json(big_dict):\n",
    "#     new_big_dict = {}\n",
    "#     new_big_dict['graph_specs'] = [big_dict['graph_specs'][0].tolist(), big_dict['graph_specs'][1].tolist()]\n",
    "#     new_big_dict['time_costs'] = [big_dict['time_costs'][0].tolist(), big_dict['time_costs'][1].tolist(), big_dict['time_costs'][2].tolist()]\n",
    "#     new_big_dict['inconsistencies'] =  [big_dict['inconsistencies'][0].tolist(), big_dict['inconsistencies'][1].tolist(), big_dict['inconsistencies'][2].tolist()]\n",
    "\n",
    "#     # write result big_dict to json\n",
    "#     with open(\"big_dict.json\",\"w\") as f:\n",
    "#         json.dump(new_big_dict,f)\n",
    "\n",
    "# def load_from_json():\n",
    "#     with open('big_dict.json') as json_file:\n",
    "#         big_dict = json.load(json_file)\n",
    "\n",
    "#     new_big_dict = {}\n",
    "#     new_big_dict['graph_specs'] = [np.array(big_dict['graph_specs'][0]), np.array(big_dict['graph_specs'][1])]\n",
    "#     new_big_dict['time_costs'] = [np.array(big_dict['time_costs'][0]), np.array(big_dict['time_costs'][1]), np.array(big_dict['time_costs'][2])]\n",
    "#     new_big_dict['inconsistencies'] =  [np.array(big_dict['inconsistencies'][0]), np.array(big_dict['inconsistencies'][1]), np.array(big_dict['inconsistencies'][2])]\n",
    "\n",
    "#     return new_big_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.Tensor([  [0, 5, torch.inf, 10],\n",
    "                    [torch.inf, 0, 3, torch.inf],\n",
    "                    [torch.inf, torch.inf, 0, 1],\n",
    "                    [torch.inf, torch.inf, torch.inf, 0] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_nx = True\n",
    "big_dict = benchmark(num_exps=1000, max_nodes=1000, max_density=100, do_nx=do_nx)\n",
    "save_to_json(big_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dict = load_from_json('big_dict2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_nx = True\n",
    "sort_by_and_plot(big_dict, sort_by='edges', do_nx=True, exp_slice=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by_and_plot(big_dict, sort_by='edges', do_nx=False, exp_slice=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apsp import FW_iter\n",
    "FW_iter(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Oct 12 2021, 13:49:34) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a505342b8f8ec6e392b07c17fb44b96227f47f39bd704660f118636a1044574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
